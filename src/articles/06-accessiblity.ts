export const content: object = {
  title: 'Bringing open source ethos to AI development, accessible to all',
  hash: '#accessiblity',
  author: {
    name: 'Moez Draief',
    job_title: 'Managing Director of Mozilla.ai',
    image: '/headshots/Moez-Draief.jpeg',
  },
  lead_article: false,
  modal_style: 'medium',
  icon: '<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 572 286"><g clip-path="url(#a)"><rect width="573" height="286" fill="#62EA8B" opacity=".5" rx="143"/><g opacity=".5" style="mix-blend-mode:multiply"><mask id="b" width="574" height="286" x="276" y="0" maskUnits="userSpaceOnUse" style="mask-type:alpha"><rect width="573" height="286" fill="#62EA8B" rx="143" transform="matrix(-1 0 0 1 849.507 0)"/></mask><g mask="url(#b)"><path fill="#62EA8B" d="M575.097 139.703C575.097 62.547 512.55 0 435.394 0H276.007v286h299.09V139.703Z" style="mix-blend-mode:multiply"/></g></g></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h573v286H0z"/></clipPath></defs></svg>',
  width: 'half',
  excerpt: 'At Mozilla.ai, we envision a future where safe guardrails lead to more sustainable and thoughtful AI innovations that bring choice to the market, enrich people’s lives and benefit society.',
  body: '<h3>Creating Open Source AI Tools for the Benefit of Everyone</h3><p>I’ve been involved in AI research and engineering for more than two decades, working to solve the technical and ethical challenges posed by AI. So I was thrilled to get the chance to join Mozilla.ai <a href="https://blog.mozilla.org/en/mozilla/introducing-mozilla-ai-investing-in-trustworthy-ai/" target="_blank">earlier this year</a> to focus on building tools that make generative AI safer and more transparent and fair.</p><p>Mozilla.ai isn’t a typical company. We’re both an AI research startup and a community of founders, developers, scientists, product managers and others who are collaborating on technology built with different values and incentives than existing tools from big incumbent companies who control the market. Our vision is to develop and foster trustworthy and independent open-source products that put people before profits.</p><p>One of the reasons a few dominant players are controlling the AI market right now is that general purpose open source large language models (LLMs) are hard to use, require special knowledge and training, and are not good for specific use cases. For instance, …</p><p>To solve this, Mozilla.ai is building a product that will bring effective language model capabilities to organizations who lack the teams and resources needed to use existing LLMs. We’ve got 15 engineers working on open source LLMs. We’re creating end-to-end safe, customizable solutions for specific groups, components that could be open-sourced to others to use, either in that industry or others.</p><p>Our offerings will start with infrastructure for collecting high quality data for training and feedback, building blocks for training small use-case specific languages, and operations tools for evaluating for trustworthiness, monitoring, and safety and security guardrails.</p><p>We’re not training language models, we’re fine tuning, or retraining them. So, we take a model that’s become fluent with data from the internet and get it to solve specific tasks. For instance, … Our goal is to use as little data as possible, but data that is high quality and curated by experts.</p><p>We work to get the models as powerful from a cognitive perspective as possible and then complement them with tools and access to knowledge that wouldn’t otherwise have access to through the neural network that’s underneath the model.</p><p>We’re looking to work with organizations that are very transparent with their documentation and asking how they collect the data, how it was cleaned and used, what decisions were made to train the algorithms and what guardrails are in place. We also want to peer into the mechanics to see how the model is thinking while it is making inferences, and understand things like the technical lingo being used in prompts that may lead to hallucinations, or false information. This is why we need open source models — to understand why LLMs give the responses they do, so we can prevent inaccuracies and bias.</p><p>To start off, we’re working with use cases in the healthcare space, helping people who have big problems to solve, and building technology for that. There’s a lot of structured data work in that industry that will feed the language models; we don’t have to invent it.</p>'
};
